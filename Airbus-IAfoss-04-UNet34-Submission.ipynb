{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "Based on https://www.kaggle.com/iafoss/unet34-submission-0-89-public-lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CUDA devices...\n",
      "Setting variables...\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting CUDA devices...\")\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\"\n",
    "\n",
    "#resnet = \"Resnet34_lable_256_1.h5\"\n",
    "#resnet = \"Resnet34_768_7.h5\"\n",
    "resnet = \"Resnet34_384_7.h5\"\n",
    "#unet = 'Unet34_256_1'\n",
    "unet_trained = 'Unet34_384_1'\n",
    "#unet = 'Unet34_768_1'\n",
    "#unet = 'Unet34_768_7'\n",
    "\n",
    "\n",
    "\n",
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "print(\"Setting variables...\")\n",
    "DATASET_ROOT = '/media/data-nvme/dev/datasets/airbus/'\n",
    "#DATASET_ROOT = '/media/data/dev/datasets/airbus/'\n",
    "PATH = DATASET_ROOT\n",
    "TRAIN = DATASET_ROOT + 'train/'\n",
    "TEST = DATASET_ROOT + 'test/'\n",
    "SEGMENTATION = DATASET_ROOT + 'train_ship_segmentations.csv'\n",
    "PRETRAINED_DETECTION_PATH = DATASET_ROOT + 'fine-tuning-resnet34-on-ship-detection/models/'\n",
    "#PRETRAINED = DATASET_ROOT + 'models/Resnet34_lable_256_1.h5'\n",
    "PRETRAINED = DATASET_ROOT + 'models/' + resnet\n",
    "\n",
    "PRETRAINED_SEGMENTATION_PATH = DATASET_ROOT + 'models/'\n",
    "DETECTION_TEST_PRED = DATASET_ROOT + 'models/ship_detection.csv'\n",
    "exclude_list = ['6384c3e78.jpg','13703f040.jpg', '14715c06d.jpg',  '33e0ff2d5.jpg',\n",
    "                '4d4e09f2a.jpg', '877691df8.jpg', '8b909bb20.jpg', 'a8d99130e.jpg', \n",
    "                'ad55c3143.jpg', 'c8260c541.jpg', 'd6c7f17c7.jpg', 'dc3e7c901.jpg',\n",
    "                'e44dffe88.jpg', 'ef87bad36.jpg', 'f083256d8.jpg'] #corrupted images\n",
    "\n",
    "nw = 6   #number of workers for data loader\n",
    "arch = resnet34 #specify target architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_names = [f for f in os.listdir(TRAIN)]\n",
    "test_names = [f for f in os.listdir(TEST)]\n",
    "for el in exclude_list:\n",
    "    if(el in train_names): train_names.remove(el)\n",
    "    if(el in test_names): test_names.remove(el)\n",
    "#5% of data in the validation set is sufficient for model evaluation\n",
    "tr_n, val_n = train_test_split(train_names, test_size=0.05, random_state=42)\n",
    "segmentation_df = pd.read_csv(os.path.join(PATH, SEGMENTATION)).set_index('ImageId')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 \n",
      " 0.20424287578056013\n"
     ]
    }
   ],
   "source": [
    "def cut_empty(names):\n",
    "    return [name for name in names \n",
    "            if(type(segmentation_df.loc[name]['EncodedPixels']) != float)]\n",
    "\n",
    "tr_n_cut = cut_empty(tr_n)\n",
    "val_n_cut = cut_empty(val_n)\n",
    "\n",
    "def get_mask(img_id, df):\n",
    "    shape = (768,768)\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    masks = df.loc[img_id]['EncodedPixels']\n",
    "    if(type(masks) == float): return img.reshape(shape)\n",
    "    if(type(masks) == str): masks = [masks]\n",
    "    for mask in masks:\n",
    "        s = mask.split()\n",
    "        for i in range(len(s)//2):\n",
    "            start = int(s[2*i]) - 1\n",
    "            length = int(s[2*i+1])\n",
    "            img[start:start+length] = 1\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "class pdFilesDataset(FilesDataset):\n",
    "    def __init__(self, fnames, path, transform):\n",
    "        self.segmentation_df = pd.read_csv(SEGMENTATION).set_index('ImageId')\n",
    "        super().__init__(fnames, transform, path)\n",
    "    \n",
    "    def get_x(self, i):\n",
    "        img = open_image(os.path.join(self.path, self.fnames[i]))\n",
    "        if self.sz == 768: return img \n",
    "        else: return cv2.resize(img, (self.sz, self.sz))\n",
    "    \n",
    "    def get_y(self, i):\n",
    "        mask = np.zeros((768,768), dtype=np.uint8) if (self.path == TEST) \\\n",
    "            else get_mask(self.fnames[i], self.segmentation_df)\n",
    "        img = Image.fromarray(mask).resize((self.sz, self.sz)).convert('RGB')\n",
    "        return np.array(img).astype(np.float32)\n",
    "    \n",
    "    def get_c(self): return 0\n",
    "    \n",
    "def get_data(sz,bs):\n",
    "    tfms = tfms_from_model(arch, sz, crop_type=CropType.NO, tfm_y=TfmType.CLASS)\n",
    "    tr_names = tr_n if (len(tr_n_cut)%bs == 0) else tr_n[:-(len(tr_n_cut)%bs)] #cut incomplete batch\n",
    "    ds = ImageData.get_ds(pdFilesDataset, (tr_names,TRAIN), \n",
    "                (val_n_cut,TRAIN), tfms, test=(test_names,TEST))\n",
    "    md = ImageData(PATH, ds, bs, num_workers=nw, classes=None)\n",
    "    #md.is_multi = False\n",
    "    return md\n",
    "############################\n",
    "####### Model\n",
    "\n",
    "cut,lr_cut = model_meta[arch]\n",
    "def get_base():                   #load ResNet34 model\n",
    "    layers = cut_model(arch(True), cut)\n",
    "    return nn.Sequential(*layers)\n",
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, up_in, x_in, n_out):\n",
    "        super().__init__()\n",
    "        up_out = x_out = n_out//2\n",
    "        self.x_conv  = nn.Conv2d(x_in,  x_out,  1)\n",
    "        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(n_out)\n",
    "        \n",
    "    def forward(self, up_p, x_p):\n",
    "        up_p = self.tr_conv(up_p)\n",
    "        x_p = self.x_conv(x_p)\n",
    "        cat_p = torch.cat([up_p,x_p], dim=1)\n",
    "        return self.bn(F.relu(cat_p))\n",
    "\n",
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = output\n",
    "    def remove(self): self.hook.remove()\n",
    "    \n",
    "class Unet34(nn.Module):\n",
    "    def __init__(self, rn):\n",
    "        super().__init__()\n",
    "        self.rn = rn\n",
    "        self.sfs = [SaveFeatures(rn[i]) for i in [2,4,5,6]]\n",
    "        self.up1 = UnetBlock(512,256,256)\n",
    "        self.up2 = UnetBlock(256,128,256)\n",
    "        self.up3 = UnetBlock(256,64,256)\n",
    "        self.up4 = UnetBlock(256,64,256)\n",
    "        self.up5 = nn.ConvTranspose2d(256, 1, 2, stride=2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.rn(x))\n",
    "        x = self.up1(x, self.sfs[3].features)\n",
    "        x = self.up2(x, self.sfs[2].features)\n",
    "        x = self.up3(x, self.sfs[1].features)\n",
    "        x = self.up4(x, self.sfs[0].features)\n",
    "        x = self.up5(x)\n",
    "        return x[:,0]\n",
    "    \n",
    "    def close(self):\n",
    "        for sf in self.sfs: sf.remove()\n",
    "            \n",
    "class UnetModel():\n",
    "    def __init__(self,model,name='Unet'):\n",
    "        self.model,self.name = model,name\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        lgs = list(split_by_idxs(children(self.model.rn), [lr_cut]))\n",
    "        return lgs + [children(self.model)[1:]]\n",
    "    \n",
    "###############\n",
    "#### Score evaluation\n",
    "def IoU(pred, targs):\n",
    "    pred = (pred > 0.5).astype(float)\n",
    "    intersection = (pred*targs).sum()\n",
    "    return intersection / ((pred+targs).sum() - intersection + 1.0)\n",
    "\n",
    "def get_score(pred, true):\n",
    "    n_th = 10\n",
    "    b = 4\n",
    "    thresholds = [0.5 + 0.05*i for i in range(n_th)]\n",
    "    n_masks = len(true)\n",
    "    n_pred = len(pred)\n",
    "    ious = []\n",
    "    score = 0\n",
    "    for mask in true:\n",
    "        buf = []\n",
    "        for p in pred: buf.append(IoU(p,mask))\n",
    "        ious.append(buf)\n",
    "    for t in thresholds:   \n",
    "        tp, fp, fn = 0, 0, 0\n",
    "        for i in range(n_masks):\n",
    "            match = False\n",
    "            for j in range(n_pred):\n",
    "                if ious[i][j] > t: match = True\n",
    "            if not match: fn += 1\n",
    "        \n",
    "        for j in range(n_pred):\n",
    "            match = False\n",
    "            for i in range(n_masks):\n",
    "                if ious[i][j] > t: match = True\n",
    "            if match: tp += 1\n",
    "            else: fp += 1\n",
    "        score += ((b+1)*tp)/((b+1)*tp + b*fn + fp)       \n",
    "    return score/n_th\n",
    "\n",
    "def split_mask(mask):\n",
    "    threshold = 0.5\n",
    "    threshold_obj = 30 #ignor predictions composed of \"threshold_obj\" pixels or less\n",
    "    labled,n_objs = ndimage.label(mask > threshold)\n",
    "    result = []\n",
    "    for i in range(n_objs):\n",
    "        obj = (labled == i + 1).astype(int)\n",
    "        if(obj.sum() > threshold_obj): result.append(obj)\n",
    "    return result\n",
    "\n",
    "def get_mask_ind(img_id, df, shape = (768,768)): #return mask for each ship\n",
    "    masks = df.loc[img_id]['EncodedPixels']\n",
    "    if(type(masks) == float): return []\n",
    "    if(type(masks) == str): masks = [masks]\n",
    "    result = []\n",
    "    for mask in masks:\n",
    "        img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "        s = mask.split()\n",
    "        for i in range(len(s)//2):\n",
    "            start = int(s[2*i]) - 1\n",
    "            length = int(s[2*i+1])\n",
    "            img[start:start+length] = 1\n",
    "        result.append(img.reshape(shape).T)\n",
    "    return result\n",
    "\n",
    "class Score_eval():\n",
    "    def __init__(self):\n",
    "        self.segmentation_df = pd.read_csv(SEGMENTATION).set_index('ImageId')\n",
    "        self.score, self.count = 0.0, 0\n",
    "        \n",
    "    def put(self,pred,name):\n",
    "        true = get_mask_ind(name, self.segmentation_df)\n",
    "        self.score += get_score(pred,true)\n",
    "        self.count += 1\n",
    "        \n",
    "    def evaluate(self):\n",
    "        return self.score/self.count\n",
    "\n",
    "\n",
    "\n",
    "#####################\n",
    "# Prediction\n",
    "\n",
    "m = to_gpu(Unet34(get_base()))\n",
    "models = UnetModel(m)\n",
    "sz = 768 #image size\n",
    "bs = 8  #batch size\n",
    "md = get_data(sz,bs)\n",
    "learn = ConvLearner(md, models)\n",
    "learn.models_path = PRETRAINED_SEGMENTATION_PATH\n",
    "learn.load(unet_trained)\n",
    "learn.models_path = PATH\n",
    "\n",
    "def model_pred(learner, dl, F_save): #if use train dl, disable shuffling\n",
    "    learner.model.eval();\n",
    "    name_list = dl.dataset.fnames\n",
    "    num_batchs = len(dl)\n",
    "    t = tqdm(iter(dl), leave=False, total=num_batchs)\n",
    "    count = 0\n",
    "    for x,y in t:\n",
    "        py = to_np(F.sigmoid(learn.model(V(x))))\n",
    "        batch_size = len(py)\n",
    "        for i in range(batch_size):\n",
    "            F_save(py[i],to_np(y[i]),name_list[count])\n",
    "            count += 1\n",
    "\n",
    "score = Score_eval()\n",
    "process_pred = lambda yp, y, name : score.put(split_mask(yp),name)\n",
    "model_pred(learn, md.val_dl, process_pred)\n",
    "print('\\n',score.evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    }
   ],
   "source": [
    "ship_detection = pd.read_csv(DETECTION_TEST_PRED)\n",
    "ship_detection.head()\n",
    "\n",
    "test_names = ship_detection.loc[ship_detection['p_ship'] > 0.5, ['id']]['id'].values.tolist()\n",
    "test_names_nothing = ship_detection.loc[ship_detection['p_ship'] <= 0.5, ['id']]['id'].values.tolist()\n",
    "len(test_names), len(test_names_nothing)\n",
    "\n",
    "md = get_data(sz,bs)\n",
    "learn.set_data(md)\n",
    "\n",
    "def decode_mask(mask, shape=(768, 768)):\n",
    "    pixels = mask.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "ship_list_dict = []\n",
    "for name in test_names_nothing:\n",
    "    ship_list_dict.append({'ImageId':name,'EncodedPixels':np.nan})\n",
    "\n",
    "def enc_test(yp, y, name):\n",
    "    masks = split_mask(yp)\n",
    "    if(len(masks) == 0): \n",
    "        ship_list_dict.append({'ImageId':name,'EncodedPixels':np.nan})\n",
    "    for mask in masks:\n",
    "        ship_list_dict.append({'ImageId':name,'EncodedPixels':decode_mask(mask)})\n",
    "\n",
    "model_pred(learn, md.test_dl, enc_test)\n",
    "pred_df = pd.DataFrame(ship_list_dict)\n",
    "pred_df.to_csv(DATASET_ROOT + 'submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 9.06M/9.06M [00:04<00:00, 2.23MB/s]\n",
      "Successfully submitted to Airbus Ship Detection Challenge"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c airbus-ship-detection -f {DATASET_ROOT}submission.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/83/9b/ac57e15fbb239c6793c8d0b7dfd1a4c4a025eaa9f791b5388a7afb515aed/kaggle-1.5.0.tar.gz (53kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 6.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<1.23.0,>=1.15 (from kaggle)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/cb/6965947c13a94236f6d4b8223e21beb4d576dc72e8130bd7880f600839b8/urllib3-1.22-py2.py3-none-any.whl (132kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 15.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10 in /media/data-nvme/dev/conda-env/FastAIv3/lib/python3.7/site-packages (from kaggle) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi in /media/data-nvme/dev/conda-env/FastAIv3/lib/python3.7/site-packages (from kaggle) (2018.10.15)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil in /media/data-nvme/dev/conda-env/FastAIv3/lib/python3.7/site-packages (from kaggle) (2.7.3)\n",
      "Requirement already satisfied, skipping upgrade: requests in /media/data-nvme/dev/conda-env/FastAIv3/lib/python3.7/site-packages (from kaggle) (2.19.1)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /media/data-nvme/dev/conda-env/FastAIv3/lib/python3.7/site-packages (from kaggle) (4.26.0)\n",
      "Collecting python-slugify (from kaggle)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /media/data-nvme/dev/conda-env/FastAIv3/lib/python3.7/site-packages (from requests->kaggle) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.8,>=2.5 in /media/data-nvme/dev/conda-env/FastAIv3/lib/python3.7/site-packages (from requests->kaggle) (2.7)\n",
      "Collecting Unidecode>=0.04.16 (from python-slugify->kaggle)\n",
      "  Using cached https://files.pythonhosted.org/packages/59/ef/67085e30e8bbcdd76e2f0a4ad8151c13a2c5bce77c85f8cad6e1f16fb141/Unidecode-1.0.22-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: kaggle\n",
      "  Running setup.py bdist_wheel for kaggle ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ben/.cache/pip/wheels/8b/21/3b/a0076243c6ae12a6215b2da515fe06b539aee7217b406e510e\n",
      "Successfully built kaggle\n",
      "\u001b[31mfastai 1.0.11 requires torchvision-nightly, which is not installed.\u001b[0m\n",
      "Installing collected packages: urllib3, Unidecode, python-slugify, kaggle\n",
      "  Found existing installation: urllib3 1.23\n",
      "    Uninstalling urllib3-1.23:\n",
      "      Successfully uninstalled urllib3-1.23\n",
      "Successfully installed Unidecode-1.0.22 kaggle-1.5.0 python-slugify-1.2.6 urllib3-1.22\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“FastAI”",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
