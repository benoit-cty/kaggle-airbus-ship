{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unet34 submission TTA (0.699 new public LB)\n",
    "https://www.kaggle.com/iafoss/unet34-submission-tta-0-699-new-public-lb#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting CUDA devices...\n"
     ]
    }
   ],
   "source": [
    "print(\"Setting CUDA devices...\")\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\"\n",
    "\n",
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from scipy import ndimage\n",
    "\n",
    "DATASET_ROOT = '/media/data-nvme/dev/datasets/airbus/V2/'\n",
    "PATH = DATASET_ROOT\n",
    "TRAIN = DATASET_ROOT + 'train_v2/'\n",
    "TEST = DATASET_ROOT + 'test_v2/'\n",
    "SEGMENTATION = DATASET_ROOT + 'train_ship_segmentations_v2.csv'\n",
    "PRETRAINED_DETECTION_PATH = DATASET_ROOT + 'models/'\n",
    "#PRETRAINED_SEGMENTATION_PATH = '../input/unet34-dice-0-87/models/'\n",
    "#DETECTION_TEST_PRED = '../input/fine-tuning-resnet34-on-ship-detection-new-data/ship_detection.csv'\n",
    "resnet = \"Resnet34_384_7.h5\"\n",
    "unet_trained = 'Unet34_384_1'\n",
    "PRETRAINED = DATASET_ROOT + 'models/' + resnet\n",
    "\n",
    "PRETRAINED_SEGMENTATION_PATH = DATASET_ROOT + 'models/'\n",
    "DETECTION_TEST_PRED = DATASET_ROOT + 'models/ship_detection.csv'\n",
    "\n",
    "\n",
    "\n",
    "nw = 2   #number of workers for data loader\n",
    "arch = resnet34 #specify target architecture\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_names = [f for f in os.listdir(TRAIN)]\n",
    "test_names = [f for f in os.listdir(TEST)]\n",
    "#5% of data in the validation set is sufficient for model evaluation\n",
    "tr_n, val_n = train_test_split(train_names, test_size=0.05, random_state=42)\n",
    "segmentation_df = pd.read_csv(os.path.join(PATH, SEGMENTATION)).set_index('ImageId')\n",
    "\n",
    "def cut_empty(names):\n",
    "    return [name for name in names \n",
    "            if(type(segmentation_df.loc[name]['EncodedPixels']) != float)]\n",
    "\n",
    "tr_n_cut = cut_empty(tr_n)\n",
    "val_n_cut = cut_empty(val_n)\n",
    "\n",
    "\n",
    "def get_mask(img_id, df):\n",
    "    shape = (768,768)\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    masks = df.loc[img_id]['EncodedPixels']\n",
    "    if(type(masks) == float): return img.reshape(shape)\n",
    "    if(type(masks) == str): masks = [masks]\n",
    "    for mask in masks:\n",
    "        s = mask.split()\n",
    "        for i in range(len(s)//2):\n",
    "            start = int(s[2*i]) - 1\n",
    "            length = int(s[2*i+1])\n",
    "            img[start:start+length] = 1\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "class pdFilesDataset(FilesDataset):\n",
    "    def __init__(self, fnames, path, transform):\n",
    "        self.segmentation_df = pd.read_csv(SEGMENTATION).set_index('ImageId')\n",
    "        super().__init__(fnames, transform, path)\n",
    "    \n",
    "    def get_x(self, i):\n",
    "        img = open_image(os.path.join(self.path, self.fnames[i]))\n",
    "        if self.sz == 768: return img \n",
    "        else: return cv2.resize(img, (self.sz, self.sz))\n",
    "    \n",
    "    def get_y(self, i):\n",
    "        mask = np.zeros((768,768), dtype=np.uint8) if (self.path == TEST) \\\n",
    "            else get_mask(self.fnames[i], self.segmentation_df)\n",
    "        img = Image.fromarray(mask).resize((self.sz, self.sz)).convert('RGB')\n",
    "        return np.array(img).astype(np.float32)\n",
    "    \n",
    "    def get_c(self): return 0\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_data(sz,bs):\n",
    "    tfms = tfms_from_model(arch, sz, crop_type=CropType.NO, tfm_y=TfmType.CLASS)\n",
    "    tr_names = tr_n if (len(tr_n_cut)%bs == 0) else tr_n[:-(len(tr_n_cut)%bs)] #cut incomplete batch\n",
    "    ds = ImageData.get_ds(pdFilesDataset, (tr_names,TRAIN), \n",
    "                (val_n_cut,TRAIN), tfms, test=(test_names,TEST))\n",
    "    md = ImageData(PATH, ds, bs, num_workers=nw, classes=None)\n",
    "    return md\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut,lr_cut = model_meta[arch]\n",
    "\n",
    "def get_base(pre=True):              #load ResNet34 model\n",
    "    layers = cut_model(arch(pre), cut)\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class UnetBlock(nn.Module):\n",
    "    def __init__(self, up_in, x_in, n_out):\n",
    "        super().__init__()\n",
    "        up_out = x_out = n_out//2\n",
    "        self.x_conv  = nn.Conv2d(x_in,  x_out,  1)\n",
    "        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, stride=2)\n",
    "        self.bn = nn.BatchNorm2d(n_out)\n",
    "        \n",
    "    def forward(self, up_p, x_p):\n",
    "        up_p = self.tr_conv(up_p)\n",
    "        x_p = self.x_conv(x_p)\n",
    "        cat_p = torch.cat([up_p,x_p], dim=1)\n",
    "        return self.bn(F.relu(cat_p))\n",
    "\n",
    "class SaveFeatures():\n",
    "    features=None\n",
    "    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
    "    def hook_fn(self, module, input, output): self.features = output\n",
    "    def remove(self): self.hook.remove()\n",
    "    \n",
    "class Unet34(nn.Module):\n",
    "    def __init__(self, rn):\n",
    "        super().__init__()\n",
    "        self.rn = rn\n",
    "        self.sfs = [SaveFeatures(rn[i]) for i in [2,4,5,6]]\n",
    "        self.up1 = UnetBlock(512,256,256)\n",
    "        self.up2 = UnetBlock(256,128,256)\n",
    "        self.up3 = UnetBlock(256,64,256)\n",
    "        self.up4 = UnetBlock(256,64,256)\n",
    "        self.up5 = nn.ConvTranspose2d(256, 1, 2, stride=2)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.rn(x))\n",
    "        x = self.up1(x, self.sfs[3].features)\n",
    "        x = self.up2(x, self.sfs[2].features)\n",
    "        x = self.up3(x, self.sfs[1].features)\n",
    "        x = self.up4(x, self.sfs[0].features)\n",
    "        x = self.up5(x)\n",
    "        return x[:,0]\n",
    "    \n",
    "    def close(self):\n",
    "        for sf in self.sfs: sf.remove()\n",
    "            \n",
    "class UnetModel():\n",
    "    def __init__(self,model,name='Unet'):\n",
    "        self.model,self.name = model,name\n",
    "\n",
    "    def get_layer_groups(self, precompute):\n",
    "        lgs = list(split_by_idxs(children(self.model.rn), [lr_cut]))\n",
    "        return lgs + [children(self.model)[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Score evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(pred, targs):\n",
    "    pred = (pred > 0.5).astype(float)\n",
    "    intersection = (pred*targs).sum()\n",
    "    return intersection / ((pred+targs).sum() - intersection + 1.0)\n",
    "\n",
    "def get_score(pred, true):\n",
    "    n_th = 10\n",
    "    b = 4\n",
    "    thresholds = [0.5 + 0.05*i for i in range(n_th)]\n",
    "    n_masks = len(true)\n",
    "    n_pred = len(pred)\n",
    "    ious = []\n",
    "    score = 0\n",
    "    for mask in true:\n",
    "        buf = []\n",
    "        for p in pred: buf.append(IoU(p,mask))\n",
    "        ious.append(buf)\n",
    "    for t in thresholds:   \n",
    "        tp, fp, fn = 0, 0, 0\n",
    "        for i in range(n_masks):\n",
    "            match = False\n",
    "            for j in range(n_pred):\n",
    "                if ious[i][j] > t: match = True\n",
    "            if not match: fn += 1\n",
    "        \n",
    "        for j in range(n_pred):\n",
    "            match = False\n",
    "            for i in range(n_masks):\n",
    "                if ious[i][j] > t: match = True\n",
    "            if match: tp += 1\n",
    "            else: fp += 1\n",
    "        score += ((b+1)*tp)/((b+1)*tp + b*fn + fp)       \n",
    "    return score/n_th\n",
    "\n",
    "def split_mask(mask):\n",
    "    threshold = 0.5\n",
    "    threshold_obj = 30 #ignor predictions composed of \"threshold_obj\" pixels or less\n",
    "    labled,n_objs = ndimage.label(mask > threshold)\n",
    "    result = []\n",
    "    for i in range(n_objs):\n",
    "        obj = (labled == i + 1).astype(int)\n",
    "        if(obj.sum() > threshold_obj): result.append(obj)\n",
    "    return result\n",
    "def get_mask_ind(img_id, df, shape = (768,768)): #return mask for each ship\n",
    "    masks = df.loc[img_id]['EncodedPixels']\n",
    "    if(type(masks) == float): return []\n",
    "    if(type(masks) == str): masks = [masks]\n",
    "    result = []\n",
    "    for mask in masks:\n",
    "        img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "        s = mask.split()\n",
    "        for i in range(len(s)//2):\n",
    "            start = int(s[2*i]) - 1\n",
    "            length = int(s[2*i+1])\n",
    "            img[start:start+length] = 1\n",
    "        result.append(img.reshape(shape).T)\n",
    "    return result\n",
    "class Score_eval():\n",
    "    def __init__(self):\n",
    "        self.segmentation_df = pd.read_csv(SEGMENTATION).set_index('ImageId')\n",
    "        self.score, self.count = 0.0, 0\n",
    "        \n",
    "    def put(self,pred,name):\n",
    "        true = get_mask_ind(name, self.segmentation_df)\n",
    "        self.score += get_score(pred,true)\n",
    "        self.count += 1\n",
    "        \n",
    "    def evaluate(self):\n",
    "        return self.score/self.count\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_unit(x,fwd=True,mask=False):\n",
    "    return x\n",
    "\n",
    "def aug_flipV(x,fwd=True,mask=False):\n",
    "    return x.flip(2) if mask else x.flip(3)\n",
    "\n",
    "def aug_flipH(x,fwd=True,mask=False):\n",
    "    return x.flip(1) if mask else x.flip(2)\n",
    "\n",
    "def aug_T(x,fwd=True,mask=False):\n",
    "    return torch.transpose(x,1,2) if mask else torch.transpose(x,2,3)\n",
    "\n",
    "def aug_rot_2(x,fwd=True,mask=False): #rotate pi/2\n",
    "    return aug_flipV(aug_flipH(x,fwd,mask),fwd,mask)\n",
    "\n",
    "def aug_rot_4cr(x,fwd=True,mask=False): #rotate pi/4 counterclockwise\n",
    "    return aug_flipV(aug_T(x,fwd,mask),fwd,mask) if fwd else \\\n",
    "        aug_T(aug_flipV(x,fwd,mask),fwd,mask)\n",
    "\n",
    "def aug_rot_4cw(x,fwd=True,mask=False): #rotate pi/4 clockwise\n",
    "    return aug_flipH(aug_T(x,fwd,mask),fwd,mask) if fwd else \\\n",
    "        aug_T(aug_flipH(x,fwd,mask),fwd,mask)\n",
    "\n",
    "def aug_rot_2T(x,fwd=True,mask=False): #transpose and rotate pi/2\n",
    "    return aug_rot_2(aug_T(x,fwd,mask),fwd,mask)\n",
    "\n",
    "trms_side_on = [aug_unit,aug_flipH]\n",
    "trms_top_down = [aug_unit,aug_flipV]\n",
    "trms_dihedral = [aug_unit,aug_flipH,aug_flipV,aug_T,aug_rot_2,aug_rot_2T,\n",
    "                 aug_rot_4cw,aug_rot_4cr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-3d30f5c64066>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ce69faa4b.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mdisplay_augs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrms_dihedral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-3d30f5c64066>\u001b[0m in \u001b[0;36mdisplay_augs\u001b[0;34m(x, augs)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-3d30f5c64066>\u001b[0m in \u001b[0;36menc_img\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0menc_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdec_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mto_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1152x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def enc_img(img):\n",
    "    return torch.transpose(torch.tensor(img),0,2).unsqueeze(0)\n",
    "\n",
    "def dec_img(img):\n",
    "    return to_np(torch.transpose(img.squeeze(0),0,2))\n",
    "\n",
    "def display_augs(x,augs=aug_unit):\n",
    "    columns = 4\n",
    "    n = len(augs)\n",
    "    rows = n//4 + 1\n",
    "    fig=plt.figure(figsize=(columns*4, rows*4))\n",
    "    img = enc_img(x)\n",
    "    for i in range(rows):\n",
    "        for j in range(columns):\n",
    "            idx = j+i*columns\n",
    "            if idx >= n: break\n",
    "            fig.add_subplot(rows, columns, idx+1)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(dec_img(augs[idx](img)))\n",
    "    plt.show()\n",
    "    \n",
    "img = np.array(Image.open(os.path.join(TRAIN,'ce69faa4b.jpg')))\n",
    "display_augs(img,trms_dihedral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[188, 183, 154],\n",
       "        [151, 145, 119],\n",
       "        [110, 106,  81],\n",
       "        ...,\n",
       "        [208, 167, 137],\n",
       "        [209, 168, 140],\n",
       "        [208, 168, 142]],\n",
       "\n",
       "       [[141, 134, 105],\n",
       "        [111, 104,  76],\n",
       "        [ 80,  74,  48],\n",
       "        ...,\n",
       "        [208, 167, 135],\n",
       "        [209, 168, 138],\n",
       "        [209, 170, 141]],\n",
       "\n",
       "       [[ 87,  78,  45],\n",
       "        [ 67,  58,  27],\n",
       "        [ 48,  41,  12],\n",
       "        ...,\n",
       "        [210, 167, 133],\n",
       "        [209, 168, 136],\n",
       "        [210, 169, 137]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 42,  56,  43],\n",
       "        [ 43,  57,  44],\n",
       "        [ 42,  56,  39],\n",
       "        ...,\n",
       "        [ 96, 112,  99],\n",
       "        [ 94, 112, 100],\n",
       "        [ 92, 110,  98]],\n",
       "\n",
       "       [[ 23,  35,  23],\n",
       "        [ 25,  39,  24],\n",
       "        [ 28,  42,  25],\n",
       "        ...,\n",
       "        [ 87, 105,  93],\n",
       "        [ 89, 106,  96],\n",
       "        [ 90, 107,  99]],\n",
       "\n",
       "       [[  5,  17,   5],\n",
       "        [  9,  21,   7],\n",
       "        [ 13,  27,  10],\n",
       "        ...,\n",
       "        [ 80,  97,  87],\n",
       "        [ 84, 101,  93],\n",
       "        [ 87, 104,  96]]], dtype=uint8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pred(learner, dl, F_save): #if use train dl, disable shuffling\n",
    "    learner.model.eval();\n",
    "    name_list = dl.dataset.fnames\n",
    "    num_batchs = len(dl)\n",
    "    t = tqdm(iter(dl), leave=False, total=num_batchs)\n",
    "    count = 0\n",
    "    for x,y in t:\n",
    "        py = to_np(torch.sigmoid(learn.model(V(x))))\n",
    "        batch_size = len(py)\n",
    "        for i in range(batch_size):\n",
    "            F_save(py[i],to_np(y[i]),name_list[count])\n",
    "            count += 1\n",
    "            \n",
    "def pred_aug(x,aug=[aug_unit]):\n",
    "    pred = []\n",
    "    for aug_cur in aug:\n",
    "        py = to_np(aug_cur(torch.sigmoid(learn.model(V(aug_cur(x)))),\n",
    "                           fwd=False, mask=True))\n",
    "        pred.append(py)\n",
    "    pred = np.stack(pred, axis=0).mean(axis=0)\n",
    "    return pred\n",
    "\n",
    "#if use train dl, disable shuffling\n",
    "def model_pred_aug(learner, dl, F_save, aug=[aug_unit]):\n",
    "    learner.model.eval();\n",
    "    name_list = dl.dataset.fnames\n",
    "    num_batchs = len(dl)\n",
    "    t = tqdm(iter(dl), leave=False, total=num_batchs)\n",
    "    count = 0\n",
    "    for x,y in t:\n",
    "        pred = pred_aug(x,aug)           \n",
    "        batch_size = len(pred)\n",
    "        for i in range(batch_size):\n",
    "            F_save(pred[i],to_np(y[i]),name_list[count])\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = to_gpu(Unet34(get_base(False)))\n",
    "models = UnetModel(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 768 #image size\n",
    "bs = 8  #batch size\n",
    "md = get_data(sz,bs)\n",
    "\n",
    "learn = ConvLearner(md, models)\n",
    "learn.models_path = PRETRAINED_SEGMENTATION_PATH\n",
    "learn.load('Unet34_768_1')\n",
    "learn.models_path = PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = Score_eval()\n",
    "process_pred = lambda yp, y, name : score.put(split_mask(yp),name)\n",
    "model_pred_aug(learn, md.val_dl, process_pred, trms_dihedral)\n",
    "print('\\n',score.evaluate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_detection = pd.read_csv(DETECTION_TEST_PRED)\n",
    "ship_detection.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_names = ship_detection.loc[ship_detection['p_ship'] > 0.5, ['id']]['id'].values.tolist()\n",
    "test_names_nothing = ship_detection.loc[ship_detection['p_ship'] <= 0.5, ['id']]['id'].values.tolist()\n",
    "len(test_names), len(test_names_nothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = get_data(sz,bs)\n",
    "learn.set_data(md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_mask(mask, shape=(768, 768)):\n",
    "    pixels = mask.T.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_list_dict = []\n",
    "for name in test_names_nothing:\n",
    "    ship_list_dict.append({'ImageId':name,'EncodedPixels':np.nan})\n",
    "def enc_test(yp, y, name):\n",
    "    masks = split_mask(yp)\n",
    "    if(len(masks) == 0): \n",
    "        ship_list_dict.append({'ImageId':name,'EncodedPixels':np.nan})\n",
    "    for mask in masks:\n",
    "        ship_list_dict.append({'ImageId':name,'EncodedPixels':decode_mask(mask)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred_aug(learn, md.test_dl, enc_test, trms_dihedral)\n",
    "pred_df = pd.DataFrame(ship_list_dict)\n",
    "pred_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c airbus-ship-detection -f {DATASET_ROOT}submission.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
